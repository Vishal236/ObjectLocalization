{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_name   x1   x2   y1   y2\n",
      "0             JPEG_20160706_121146_1000145715002.png  115  495  143  325\n",
      "1             JPEG_20161119_174038_1000690577600.png   23  457   61  409\n",
      "2  147444927651111470309333776-Roadster-Men-Casua...   37  601   13  470\n",
      "3                   147772332675720161028_161611.png   27  602  162  385\n",
      "4                   1473315333651DeeplearnS11638.png   60  586  174  325\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"training.csv\")\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "X_train = []\n",
    "for j in range(data.shape[0]) :\n",
    "    dir = str(\"A:/images/images/\" + str(data.iloc[j,0])) \n",
    "    temp = cv2.imread(dir.strip(),0)\n",
    "    resize = cv2.resize(temp,(160,120))\n",
    "    X_train.append(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 120, 160)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train,dtype = np.uint8)/255\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 160, 120, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((14000,160,120,1))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout, Conv2D, AveragePooling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(16,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Conv2D(32,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(32,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(64,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Conv2D(128,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(128,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Conv2D(256,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(256,(3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048,activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048,activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048,activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(4,activation = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = data.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12600 samples, validate on 1400 samples\n",
      "Epoch 1/100\n",
      "12600/12600 [==============================] - 258s 20ms/step - loss: 9177.0992 - val_loss: 4283.2639\n",
      "Epoch 2/100\n",
      "12600/12600 [==============================] - 255s 20ms/step - loss: 4859.6282 - val_loss: 4940.6005\n",
      "Epoch 3/100\n",
      "12600/12600 [==============================] - 258s 20ms/step - loss: 4789.7477 - val_loss: 4257.9182\n",
      "Epoch 4/100\n",
      "12600/12600 [==============================] - 255s 20ms/step - loss: 4638.2354 - val_loss: 4123.6205\n",
      "Epoch 5/100\n",
      "12600/12600 [==============================] - 255s 20ms/step - loss: 4509.4533 - val_loss: 4041.7424\n",
      "Epoch 6/100\n",
      "12600/12600 [==============================] - 254s 20ms/step - loss: 4357.3160 - val_loss: 4241.2436\n",
      "Epoch 7/100\n",
      "12600/12600 [==============================] - 254s 20ms/step - loss: 3377.7390 - val_loss: 2757.7198\n",
      "Epoch 8/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 2632.2263 - val_loss: 1901.3908\n",
      "Epoch 9/100\n",
      "12600/12600 [==============================] - 254s 20ms/step - loss: 2108.9460 - val_loss: 1802.9091\n",
      "Epoch 10/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 1912.0381 - val_loss: 1496.8254\n",
      "Epoch 11/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 1761.2346 - val_loss: 1492.1108\n",
      "Epoch 12/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 1652.3185 - val_loss: 1439.1422\n",
      "Epoch 13/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 1572.3214 - val_loss: 1531.0945\n",
      "Epoch 14/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 1511.9787 - val_loss: 1464.0817\n",
      "Epoch 15/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 1413.3814 - val_loss: 1274.2282\n",
      "Epoch 16/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 1279.3167 - val_loss: 1031.1508\n",
      "Epoch 17/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 1147.7210 - val_loss: 1040.7974\n",
      "Epoch 18/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 1071.6998 - val_loss: 953.2881\n",
      "Epoch 19/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 999.0796 - val_loss: 1143.7065\n",
      "Epoch 20/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 979.4209 - val_loss: 977.2722\n",
      "Epoch 21/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 911.9738 - val_loss: 988.1580\n",
      "Epoch 22/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 873.6534 - val_loss: 984.3306\n",
      "Epoch 23/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 816.0419 - val_loss: 954.9318\n",
      "Epoch 24/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 799.7181 - val_loss: 934.1274\n",
      "Epoch 25/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 743.7020 - val_loss: 929.7127\n",
      "Epoch 26/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 751.4890 - val_loss: 922.4252\n",
      "Epoch 27/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 691.9488 - val_loss: 940.1798\n",
      "Epoch 28/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 675.7056 - val_loss: 868.7973\n",
      "Epoch 29/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 634.0616 - val_loss: 1041.1407\n",
      "Epoch 30/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 626.9135 - val_loss: 875.7765\n",
      "Epoch 31/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 611.9587 - val_loss: 864.1208\n",
      "Epoch 32/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 592.2338 - val_loss: 866.2454\n",
      "Epoch 33/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 569.7100 - val_loss: 921.3204\n",
      "Epoch 34/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 574.1226 - val_loss: 903.1484\n",
      "Epoch 35/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 573.2581 - val_loss: 913.0033\n",
      "Epoch 36/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 563.7075 - val_loss: 895.4130\n",
      "Epoch 37/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 542.7161 - val_loss: 860.3341\n",
      "Epoch 38/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 559.1048 - val_loss: 941.6160\n",
      "Epoch 39/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 536.4104 - val_loss: 839.3184\n",
      "Epoch 40/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 523.0777 - val_loss: 890.6657\n",
      "Epoch 41/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 507.5959 - val_loss: 867.8609\n",
      "Epoch 42/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 510.8479 - val_loss: 905.5802\n",
      "Epoch 43/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 523.4731 - val_loss: 860.1363\n",
      "Epoch 44/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 505.8338 - val_loss: 817.4660\n",
      "Epoch 45/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 504.4402 - val_loss: 857.3949\n",
      "Epoch 46/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 488.6403 - val_loss: 843.8309\n",
      "Epoch 47/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 517.3668 - val_loss: 844.1587\n",
      "Epoch 48/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 488.2539 - val_loss: 863.9860\n",
      "Epoch 49/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 480.5781 - val_loss: 845.4938\n",
      "Epoch 50/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 523.3569 - val_loss: 872.0411\n",
      "Epoch 51/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 501.5265 - val_loss: 879.2828\n",
      "Epoch 52/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 485.7856 - val_loss: 849.3867\n",
      "Epoch 53/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 466.5393 - val_loss: 815.8729\n",
      "Epoch 54/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 456.5777 - val_loss: 837.2477\n",
      "Epoch 55/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 467.3248 - val_loss: 832.9484\n",
      "Epoch 56/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 484.1024 - val_loss: 871.9979\n",
      "Epoch 57/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 456.7258 - val_loss: 800.3337\n",
      "Epoch 58/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 463.9282 - val_loss: 802.3320\n",
      "Epoch 59/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 457.3525 - val_loss: 958.3914\n",
      "Epoch 60/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 444.1749 - val_loss: 874.9466\n",
      "Epoch 61/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 472.6865 - val_loss: 877.3165\n",
      "Epoch 62/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 473.3984 - val_loss: 912.6628\n",
      "Epoch 63/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 446.9657 - val_loss: 897.2352\n",
      "Epoch 64/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 459.6119 - val_loss: 817.1558\n",
      "Epoch 65/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 445.5456 - val_loss: 849.8374\n",
      "Epoch 66/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 439.9209 - val_loss: 860.1386\n",
      "Epoch 67/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 434.5794 - val_loss: 840.6726\n",
      "Epoch 68/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 421.4886 - val_loss: 845.1641\n",
      "Epoch 69/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 431.4418 - val_loss: 814.4882\n",
      "Epoch 70/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 432.6191 - val_loss: 881.1165\n",
      "Epoch 71/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 442.8459 - val_loss: 876.8942\n",
      "Epoch 72/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 432.4924 - val_loss: 836.4934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 418.8023 - val_loss: 852.1177\n",
      "Epoch 74/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 431.1022 - val_loss: 872.8896\n",
      "Epoch 75/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 446.3608 - val_loss: 881.2276\n",
      "Epoch 76/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 418.2154 - val_loss: 798.9413\n",
      "Epoch 77/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 413.9376 - val_loss: 829.7635\n",
      "Epoch 78/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 427.8284 - val_loss: 882.6122\n",
      "Epoch 79/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 440.4217 - val_loss: 871.1211\n",
      "Epoch 80/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 420.8558 - val_loss: 900.7134\n",
      "Epoch 81/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 418.5600 - val_loss: 858.0606\n",
      "Epoch 82/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 406.1817 - val_loss: 817.5404\n",
      "Epoch 83/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 410.0683 - val_loss: 866.1025\n",
      "Epoch 84/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 420.3287 - val_loss: 869.7840\n",
      "Epoch 85/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 411.1937 - val_loss: 837.2158\n",
      "Epoch 86/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 401.4307 - val_loss: 813.1356\n",
      "Epoch 87/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 409.6204 - val_loss: 828.3091\n",
      "Epoch 88/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 392.1552 - val_loss: 824.5891\n",
      "Epoch 89/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 412.9283 - val_loss: 845.4362\n",
      "Epoch 90/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 405.0816 - val_loss: 842.9916\n",
      "Epoch 91/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 416.5709 - val_loss: 850.3014\n",
      "Epoch 92/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 393.8032 - val_loss: 806.5268\n",
      "Epoch 93/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 432.1419 - val_loss: 854.3950\n",
      "Epoch 94/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 397.4407 - val_loss: 820.1682\n",
      "Epoch 95/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 393.4306 - val_loss: 829.0810\n",
      "Epoch 96/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 407.4808 - val_loss: 870.5807\n",
      "Epoch 97/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 404.1595 - val_loss: 850.1052\n",
      "Epoch 98/100\n",
      "12600/12600 [==============================] - 252s 20ms/step - loss: 394.8294 - val_loss: 838.3928\n",
      "Epoch 99/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 390.9278 - val_loss: 795.5522\n",
      "Epoch 100/100\n",
      "12600/12600 [==============================] - 253s 20ms/step - loss: 398.7055 - val_loss: 807.2959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29dd1912828>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs = 100,batch_size=32,validation_split = 0.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 160, 120, 16)      160       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 160, 120, 16)      2320      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_11 (Averag (None, 80, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 80, 60, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 80, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_12 (Averag (None, 40, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 40, 30, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 40, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_13 (Averag (None, 20, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 20, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 20, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 10, 7, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 10, 7, 256)        295168    \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 10, 7, 256)        590080    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 5, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2048)              7866368   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 17,445,748\n",
      "Trainable params: 17,445,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"testing.csv\")\n",
    "import cv2\n",
    "X_test = []\n",
    "for j in range(dat.shape[0]) :\n",
    "    dir = str(\"A:/images/images/\" + str(dat.iloc[j,0])) \n",
    "    temp = cv2.imread(dir.strip(),0)\n",
    "    resize = cv2.resize(temp,(160,120))\n",
    "    X_test.append(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)/255\n",
    "X_test = X_test.reshape((12815,160,120,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(x = X_test,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.iloc[:,1:] = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(\"testing.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
